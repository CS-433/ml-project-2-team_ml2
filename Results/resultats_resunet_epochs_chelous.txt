C:\Users\swann\AppData\Local\Programs\Python\Python39\python.exe C:\Users\swann\ML_GitHub\MA1_ML_Project2\run.py 
Data Loaded!
CUDA IS AVAILABLE!
Data_set size : 800
Data_set size : 800
Train Epoch: 1-000 batch_loss=1.18e+06 batch_acc=0.003 lr=1.000e-03 
Train Epoch: 1-026 batch_loss=9.32e+05 batch_acc=0.458 lr=9.990e-04 
Train Epoch: 1-052 batch_loss=1.51e+06 batch_acc=0.725 lr=9.961e-04 
Train Epoch: 1-078 batch_loss=1.61e+06 batch_acc=0.723 lr=9.914e-04 
Train Epoch: 1-104 batch_loss=9.68e+05 batch_acc=0.564 lr=9.848e-04 
Train Epoch: 1-130 batch_loss=1.23e+06 batch_acc=0.748 lr=9.764e-04 
Train Epoch: 1-156 batch_loss=1.42e+06 batch_acc=0.794 lr=9.662e-04 
Train Epoch: 1-182 batch_loss=9.68e+05 batch_acc=0.707 lr=9.542e-04 
Train Epoch: 1-208 batch_loss=1.25e+06 batch_acc=0.724 lr=9.406e-04 
Train Epoch: 1-234 batch_loss=1.24e+06 batch_acc=0.702 lr=9.253e-04 
Train Epoch: 1-260 batch_loss=1.25e+06 batch_acc=0.742 lr=9.084e-04 
Test set: Average loss: 1225522.1250, Accuracy: 162.15142291666652/267 (61%)
Train Epoch: 2-000 batch_loss=9.86e+05 batch_acc=0.705 lr=9.035e-04 
Train Epoch: 2-026 batch_loss=1.12e+06 batch_acc=0.740 lr=8.847e-04 
Train Epoch: 2-052 batch_loss=1.49e+06 batch_acc=0.761 lr=8.644e-04 
Train Epoch: 2-078 batch_loss=5.63e+05 batch_acc=0.655 lr=8.428e-04 
Train Epoch: 2-104 batch_loss=1.33e+06 batch_acc=0.749 lr=8.198e-04 
Train Epoch: 2-130 batch_loss=1.38e+06 batch_acc=0.759 lr=7.957e-04 
Train Epoch: 2-156 batch_loss=9.83e+05 batch_acc=0.803 lr=7.705e-04 
Train Epoch: 2-182 batch_loss=1.30e+06 batch_acc=0.789 lr=7.442e-04 
Train Epoch: 2-208 batch_loss=1.26e+06 batch_acc=0.723 lr=7.170e-04 
Train Epoch: 2-234 batch_loss=1.27e+06 batch_acc=0.772 lr=6.890e-04 
Train Epoch: 2-260 batch_loss=6.94e+05 batch_acc=0.617 lr=6.603e-04 
Test set: Average loss: 1219478.6250, Accuracy: 202.91396979166674/267 (76%)
Train Epoch: 3-000 batch_loss=1.37e+06 batch_acc=0.676 lr=6.525e-04 
Train Epoch: 3-026 batch_loss=9.48e+05 batch_acc=0.682 lr=6.230e-04 
Train Epoch: 3-052 batch_loss=5.61e+05 batch_acc=0.636 lr=5.931e-04 
Train Epoch: 3-078 batch_loss=1.51e+06 batch_acc=0.661 lr=5.629e-04 
Train Epoch: 3-104 batch_loss=1.35e+06 batch_acc=0.716 lr=5.324e-04 
Train Epoch: 3-130 batch_loss=1.26e+06 batch_acc=0.732 lr=5.018e-04 
Train Epoch: 3-156 batch_loss=1.29e+06 batch_acc=0.799 lr=4.711e-04 
Train Epoch: 3-182 batch_loss=8.17e+05 batch_acc=0.607 lr=4.406e-04 
Train Epoch: 3-208 batch_loss=1.39e+06 batch_acc=0.763 lr=4.103e-04 
Train Epoch: 3-234 batch_loss=9.49e+05 batch_acc=0.649 lr=3.804e-04 
Train Epoch: 3-260 batch_loss=1.12e+06 batch_acc=0.733 lr=3.509e-04 
Test set: Average loss: 1215557.2500, Accuracy: 201.3302531250001/267 (75%)
Train Epoch: 4-000 batch_loss=1.02e+06 batch_acc=0.707 lr=3.430e-04 
Train Epoch: 4-026 batch_loss=1.05e+06 batch_acc=0.701 lr=3.143e-04 
Train Epoch: 4-052 batch_loss=1.17e+06 batch_acc=0.716 lr=2.862e-04 
Train Epoch: 4-078 batch_loss=1.15e+06 batch_acc=0.563 lr=2.589e-04 
Train Epoch: 4-104 batch_loss=1.22e+06 batch_acc=0.660 lr=2.325e-04 
Train Epoch: 4-130 batch_loss=1.36e+06 batch_acc=0.667 lr=2.072e-04 
Train Epoch: 4-156 batch_loss=1.14e+06 batch_acc=0.539 lr=1.829e-04 
Train Epoch: 4-182 batch_loss=1.94e+06 batch_acc=0.603 lr=1.598e-04 
Train Epoch: 4-208 batch_loss=1.30e+06 batch_acc=0.507 lr=1.380e-04 
Train Epoch: 4-234 batch_loss=1.16e+06 batch_acc=0.368 lr=1.176e-04 
Train Epoch: 4-260 batch_loss=1.51e+06 batch_acc=0.320 lr=9.856e-05 
Test set: Average loss: 1212815.3750, Accuracy: 65.231096875/267 (24%)
Train Epoch: 5-000 batch_loss=1.25e+06 batch_acc=0.263 lr=9.370e-05 
Train Epoch: 5-026 batch_loss=1.15e+06 batch_acc=0.203 lr=7.662e-05 
Train Epoch: 5-052 batch_loss=1.40e+06 batch_acc=0.221 lr=6.112e-05 
Train Epoch: 5-078 batch_loss=8.89e+05 batch_acc=0.168 lr=4.728e-05 
Train Epoch: 5-104 batch_loss=1.70e+06 batch_acc=0.287 lr=3.513e-05 
Train Epoch: 5-130 batch_loss=1.44e+06 batch_acc=0.215 lr=2.473e-05 
Train Epoch: 5-156 batch_loss=1.17e+06 batch_acc=0.186 lr=1.611e-05 
Train Epoch: 5-182 batch_loss=1.47e+06 batch_acc=0.167 lr=9.308e-06 
Train Epoch: 5-208 batch_loss=1.28e+06 batch_acc=0.169 lr=4.348e-06 
Train Epoch: 5-234 batch_loss=1.43e+06 batch_acc=0.151 lr=1.249e-06 
Train Epoch: 5-260 batch_loss=1.13e+06 batch_acc=0.145 lr=2.222e-08 
Test set: Average loss: 1210724.8750, Accuracy: 43.69761666666671/267 (16%)

Process finished with exit code 0
